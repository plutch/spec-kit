---
description: Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.
scripts:
  sh: .specify/scripts/bash/check-prerequisites.sh --json
  ps: .specify/scripts/powershell/check-prerequisites.ps1 -Json
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Outline

## Context Loading (v2.7 - Context Optimization)

**Purpose**: Load relevant memory content for task generation, optimized for token efficiency.

**Current Phase**: `tasks` (task breakdown phase)

**Context Loading Strategy**:

a. **Read Configuration** (if exists):
   - Check for `.specify/config.yml` or `.specify/config.example.yml`
   - Extract `context_budget.implementation` (default: 50KB - tasks shares budget with implementation)
   - Extract `memory.strict_phase_loading` (default: true)
   - Extract `budget_enforcement.mode` (default: strict)

b. **Load Memory Files** (phase-aware):

   For each memory file in `.specify/memory/`:

   i. **Read YAML Frontmatter**:
      - Extract `inclusion_mode`, `context_level`, `load_phases`, `exclude_phases`
      - If metadata missing: Default to `inclusion_mode: always, context_level: strategic, load_phases: all`

   ii. **Determine if file should be loaded**:
      ```yaml
      IF current_phase IN exclude_phases:
        â†’ SKIP this file entirely

      ELSE IF inclusion_mode = "always":
        â†’ Load tactical sections (task templates, implementation procedures)

      ELSE IF inclusion_mode = "conditional":
        IF current_phase IN load_phases OR "tasks" IN load_phases OR "implementation" IN load_phases:
          â†’ Load tactical sections (task breakdown patterns, implementation procedures)
        ELSE:
          â†’ SKIP (e.g., specification-only content excluded)

      ELSE IF inclusion_mode = "manual":
        â†’ SKIP (manual loading via @filename only)
      ```

   iii. **Filter Sections** (if loading file):
      - Scan for `<!-- SECTION_META: context_level=X, load_phases=Y -->` comments
      - For tasks phase: Load sections where `tasks` OR `implementation` IN load_phases
      - Load tactical sections (task templates, implementation procedures, file structure patterns)
      - Skip strategic sections (high-level principles without actionable details)

   iv. **Track Budget**:
      - Sum loaded content size
      - If exceeds `context_budget.implementation` (50KB):
        - **strict mode**: Warn user, prioritize task templates + implementation procedures
        - **warn mode**: Continue loading, warn about budget exceeded
        - **adaptive mode**: Intelligently filter content to fit budget

c. **Context Loading Report** (verbose mode):

   IF `verbose_context_loading: true` in config:
   ```markdown
   ğŸ“Š Context Loading Report

   Phase: tasks
   Budget: 50KB

   Loaded:
   - task-templates.md (tactical: task breakdown patterns): 7.2KB
   - testing-approach.md (tactical: test task patterns): 8.5KB
   - file-structure-patterns.md (tactical: project organization): 5.3KB
   - Skipped: constitution.md (strategic: principles only, not task details)
   - Skipped: deployment-runbook.md (manual only)

   Total Loaded: 21KB / 50KB (42% budget used)
   Remaining: 29KB available

   Status: âœ… Within budget
   ```

d. **Backward Compatibility**:
   - If `.specify/memory/` doesn't exist â†’ Skip context loading (no error)
   - If memory files lack metadata â†’ Load all content (v2.6 behavior)
   - Never fail command due to missing memory files

**Expected Token Savings**: ~15% (30-40KB â†’ 25-35KB for tasks phase)

**Key Difference from Other Phases**:
- Tasks loads TACTICAL content (task templates, implementation procedures, file structure)
- Specification/Planning load STRATEGIC (principles, patterns, architecture)
- This ensures tasks have actionable implementation details, not just high-level principles

## Execution Steps

1. **Setup**: Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").

2. **Load design documents**: Read from FEATURE_DIR:
   - **Required**: plan.md (tech stack, libraries, structure), spec.md (user stories with priorities)
   - **Optional**: data-model.md (entities), contracts/ (API endpoints), research.md (decisions), quickstart.md (test scenarios)
   - Note: Not all projects have all documents. Generate tasks based on what's available.

3. **Execute task generation workflow**:
   - Load plan.md and extract tech stack, libraries, project structure
   - Load spec.md and extract user stories with their priorities (P1, P2, P3, etc.)
   - If data-model.md exists: Extract entities and map to user stories
   - If contracts/ exists: Map endpoints to user stories
   - If research.md exists: Extract decisions for setup tasks
   - Generate tasks organized by user story (see Task Generation Rules below)
   - Generate dependency graph showing user story completion order
   - Create parallel execution examples per user story
   - Validate task completeness (each user story has all needed tasks, independently testable)

4. **Generate tasks.md**: Use `.specify/templates/tasks-template.md` as structure, fill with:
   - Correct feature name from plan.md
   - Phase 1: Setup tasks (project initialization)
   - Phase 2: Foundational tasks (blocking prerequisites for all user stories)
   - Phase 3+: One phase per user story (in priority order from spec.md)
   - Each phase includes: story goal, independent test criteria, tests (if requested), implementation tasks
   - Final Phase: Polish & cross-cutting concerns
   - All tasks must follow the strict checklist format (see Task Generation Rules below)
   - Clear file paths for each task
   - Dependencies section showing story completion order
   - Parallel execution examples per story
   - Implementation strategy section (MVP first, incremental delivery)

5. **Report**: Output path to generated tasks.md and summary:
   - Total task count
   - Task count per user story
   - Parallel opportunities identified
   - Independent test criteria for each story
   - Suggested MVP scope (typically just User Story 1)
   - Format validation: Confirm ALL tasks follow the checklist format (checkbox, ID, labels, file paths)

6. **Task List Review Gate** (Evidence-Based Self-Check):

   **Purpose**: Validate task list completeness and readiness to proceed to implementation phase.

   **MANDATORY: The Four Task List Questions** (MUST answer with ACTUAL evidence):

   â“ **"Does each user story have complete task coverage?"**
      ```yaml
      Action Required:
        - Review tasks.md phase structure
        - For each user story phase, verify:
          - Models for entities in that story
          - Services for business logic
          - Endpoints/UI for user interactions
          - Tests (if TDD requested)
          - Integration tasks
        - Map user stories from spec.md to task phases
        - Show ACTUAL task counts per story, not summaries

      Expected Evidence Format:
        User Story Coverage:

        User Story 1 (P1): [Story name from spec.md]
        âœ“ Models: [X tasks] - [list task IDs]
        âœ“ Services: [Y tasks] - [list task IDs]
        âœ“ Endpoints/UI: [Z tasks] - [list task IDs]
        âœ“ Tests: [N tasks] - [list task IDs] (if TDD)
        âœ“ Integration: [M tasks] - [list task IDs]
        Total: [X+Y+Z+N+M] tasks
        Independent test criteria: [Yes/No] - [criteria from tasks.md]

        User Story 2 (P2): [Story name from spec.md]
        [... same structure ...]

        [Repeat for all user stories]

      Completeness Check:
        - [ ] All user stories from spec.md have task phases
        - [ ] Each story has models, services, endpoints
        - [ ] Each story has independent test criteria
        - [ ] Setup/Foundational phases complete
        - [ ] Polish phase includes cross-cutting concerns

      Readiness Determination:
        IF all user stories covered AND all checklists pass:
          â†’ âœ… Complete coverage
        IF â‰¥90% coverage AND minor gaps documented:
          â†’ âš ï¸ Minor gaps (can proceed with noted risks)
        IF <90% coverage OR major story gaps:
          â†’ âŒ Incomplete (regenerate tasks)
      ```

   â“ **"Are tasks properly formatted and executable?"**
      ```yaml
      Action Required:
        - Scan tasks.md for format violations
        - Verify EVERY task follows checklist format:
          - [ ] [TaskID] [P?] [Story?] Description with file path
        - Check task IDs are sequential (T001, T002, T003...)
        - Validate story labels match user stories from spec.md
        - Ensure file paths are specific and absolute

      Expected Evidence Format:
        Format Validation:
        âœ“ Total tasks: [N]
        âœ“ Tasks with checkboxes: [N]/[N] (100%)
        âœ“ Tasks with IDs: [N]/[N] (100%)
        âœ“ Tasks with file paths: [N]/[N] (100%)
        âœ“ Parallel tasks marked [P]: [X] tasks
        âœ“ Story-labeled tasks [USn]: [Y] tasks

        Format Violations (if any):
        - Line [N]: [Issue description]
        - Line [M]: [Issue description]

        Task ID Sequence Check:
        âœ“ Sequential: [Yes/No]
        âœ“ Range: T001 â†’ T[max]
        âœ“ Gaps/duplicates: [None/list them]

        Story Label Validation:
        âœ“ User Stories in spec.md: [US1, US2, US3, ...]
        âœ“ Story labels used in tasks: [US1, US2, US3, ...]
        âœ“ Match: [Yes/No - if No, list mismatches]

      Executability Check:
        - [ ] Each task has specific file path
        - [ ] Each task has clear action verb
        - [ ] Tasks executable without additional context
        - [ ] Dependencies clear from phase structure

      IF format violations OR executability fails:
        â†’ âŒ Tasks not properly formatted
        â†’ Fix violations before implementation
      ```

   â“ **"Are dependencies and parallelization correct?"**
      ```yaml
      Action Required:
        - Review dependency graph in tasks.md
        - Verify user story completion order makes sense
        - Check parallel markers [P] are safe:
          - Different files
          - No dependencies on incomplete tasks
        - Validate foundational phase blocks user stories
        - Ensure MVP scope is clear (typically US1)

      Expected Evidence Format:
        Dependency Structure:
        âœ“ Phase 1 (Setup): [X tasks] - No dependencies
        âœ“ Phase 2 (Foundational): [Y tasks] - Blocks user stories
        âœ“ Phase 3+ (User Stories): [Z phases] in priority order

        User Story Dependencies:
        - US1 (P1): Independent (can implement first) âœ…
        - US2 (P2): Depends on [US1/Foundational/Independent]
        - US3 (P3): Depends on [...]
        [... list all user story dependencies ...]

        Parallelization Opportunities:
        âœ“ Parallel tasks per story: [N] tasks marked [P]
        âœ“ Parallel tasks validation:
          - All [P] tasks operate on different files: [Yes/No]
          - No [P] tasks depend on incomplete work: [Yes/No]

        Parallel Execution Examples (from tasks.md):
        [Copy examples from tasks.md showing how to run parallel tasks]

        MVP Scope:
        âœ“ Recommended: User Story [X] ([Name])
        âœ“ Tasks in MVP: [N] tasks (T001-TXXX)
        âœ“ MVP deliverable: [Description of what MVP enables]

      Safety Checks:
        - [ ] Foundational tasks complete before user stories
        - [ ] No circular dependencies between stories
        - [ ] Parallel tasks truly independent
        - [ ] MVP is smallest testable increment

      IF dependency errors OR unsafe parallelization:
        â†’ âŒ Task ordering incorrect
        â†’ Fix dependencies before implementation
      ```

   â“ **"Is there evidence of task list quality?"**
      ```yaml
      Required Evidence (ALL must be provided):

      1. File Verification (MANDATORY):
         Run: ls -la [FEATURE_DIR]
         Output:
           âœ“ tasks.md: [size] bytes, [timestamp]
           âœ“ Exists: Yes/No

      2. Task Count Validation (MANDATORY):
         Run: grep -c "^- \[ \]" tasks.md
         Output:
           Total tasks: [N]

         Per-phase breakdown:
         - Setup: [X] tasks
         - Foundational: [Y] tasks
         - User Story phases: [Z] tasks across [P] phases
         - Polish: [W] tasks

      3. Format Compliance Check (MANDATORY):
         Run format validation grep commands:
         - Tasks with checkboxes: grep -c "^- \[ \]" tasks.md â†’ [N]
         - Tasks with IDs: grep -c "\[T[0-9]\{3\}\]" tasks.md â†’ [N]
         - Tasks with [P]: grep -c "\[P\]" tasks.md â†’ [X]
         - Tasks with [US: grep -c "\[US[0-9]\]" tasks.md â†’ [Y]

         Target: All counts should match or exceed expectations

      4. Spec-to-Tasks Traceability (MANDATORY):
         User Story Coverage:
         - Total user stories in spec.md: [N]
         - User stories with task phases: [M]
         - Coverage: [M/N * 100]%

         Target: 100% coverage

         Missing Coverage (if any):
         - [User Story X]: No task phase - [Why]

      5. Parallel Opportunity Analysis (MANDATORY):
         Run: grep -c "\[P\]" tasks.md
         Output:
           Parallelizable tasks: [X]
           Total tasks: [N]
           Parallelization ratio: [X/N * 100]%

         Expected: â‰¥30% for efficient implementation

      IF any evidence is MISSING:
        âŒ CANNOT report completion
        â†’ Gather missing evidence first
        â†’ Re-run this step with complete evidence
      ```

   **Hallucination Prevention (7 Red Flags for Task Generation):**
   ```yaml
   Detect and BLOCK these patterns:

   ğŸš¨ "All user stories covered" WITHOUT showing task mapping
      â†’ Self-correction: "Wait, I need to map each story to tasks"

   ğŸš¨ "Tasks generated" WITHOUT format validation
      â†’ Self-correction: "Let me verify all tasks follow checklist format"

   ğŸš¨ "Complete task list" WITH missing user stories
      â†’ Self-correction: "Some user stories have no task phases"

   ğŸš¨ Claiming executability WITHOUT file paths
      â†’ Self-correction: "Tasks need specific file paths"

   ğŸš¨ Marking tasks [P] WITHOUT checking dependencies
      â†’ Self-correction: "I need to verify parallel tasks are safe"

   ğŸš¨ Skipping traceability validation
      â†’ Self-correction: "I must map tasks back to requirements"

   ğŸš¨ "Ready for implementation" statements WITHOUT evidence
      â†’ Self-correction: "Need to verify completeness criteria first"

   IF detected: STOP â†’ Gather evidence â†’ Report honestly
   ```

   **Determine Status**:

   âœ… **READY for Implementation**:
   ```yaml
   Criteria (ALL must be met):
     - 100% user story coverage (all stories have task phases)
     - All tasks follow checklist format (checkbox, ID, story label, file path)
     - Dependencies logical (foundational blocks stories, no cycles)
     - Parallelization safe (different files, no incomplete dependencies)
     - MVP scope clear and testable
     - Independent test criteria for each story

   IF ALL criteria met:
     â†’ Proceed to Step 7 (present completion report)
   ```

   âš ï¸ **NEEDS REVIEW** (with risks noted):
   ```yaml
   Criteria:
     - â‰¥90% user story coverage (minor gaps documented)
     - Most tasks properly formatted (â‰¤5 format violations)
     - Dependencies mostly correct
     - MVP scope clear

   IF criteria met:
     â†’ Present risks to user
     â†’ Ask: "Minor gaps/format issues. Proceed to implementation or fix tasks?"
     â†’ Wait for user decision before Step 7
   ```

   âŒ **NOT READY** (regeneration needed):
   ```yaml
   Criteria (ANY triggers NOT READY):
     - <90% user story coverage
     - Significant format violations (>5 tasks)
     - Circular dependencies or blocking issues
     - Unsafe parallelization
     - MVP scope unclear
     - Missing independent test criteria

   IF NOT READY:
     â†’ Present issues to user with evidence
     â†’ Recommend: "Regenerate tasks.md addressing [specific issues]"
     â†’ STOP before Step 7 (do not proceed to implementation)
   ```

   **Output Format** (Present to User - ONLY if evidence provided):
   ```markdown
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   âœ… Task List Review Complete
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   Status: [âœ… READY | âš ï¸ NEEDS REVIEW | âŒ NOT READY]

   Branch: [branch-name]
   Tasks: [path/to/tasks.md]

   ## User Story Coverage

   Total User Stories: [N]
   Covered: [M]/[N] ([X]%)

   User Story 1 (P1): [Name]
   âœ“ Tasks: [X] (T001-TXXX)
   âœ“ Models: [Y], Services: [Z], Endpoints: [W]
   âœ“ Independent test: [criteria]

   User Story 2 (P2): [Name]
   âœ“ Tasks: [X] (TXXX-TYYY)
   [... same structure ...]

   [List all user stories with task breakdown]

   ## Task Format Validation

   âœ“ Total tasks: [N]
   âœ“ Checklist format: [N]/[N] (100%)
   âœ“ Task IDs sequential: T001 â†’ T[max]
   âœ“ File paths specific: [N]/[N] (100%)
   âœ“ Story labels match spec: [Yes/No]

   [IF format violations:]
   Format Issues:
   - Line [X]: [Issue]

   ## Dependency & Parallelization

   Phase Structure:
   âœ“ Phase 1 (Setup): [X] tasks
   âœ“ Phase 2 (Foundational): [Y] tasks - Blocks user stories
   âœ“ Phase 3+ (Stories): [Z] phases in priority order
   âœ“ Final Phase (Polish): [W] tasks

   User Story Dependencies:
   - US1: Independent âœ…
   - US2: Depends on [US1/Foundational/etc.]
   [... list all ...]

   Parallelization:
   âœ“ Parallel tasks: [X]/[N] ([Y]%)
   âœ“ Safe parallelization: [Yes/No]
   âœ“ Parallel examples provided: [Yes/No]

   MVP Scope:
   âœ“ Recommended: [User Story name]
   âœ“ Tasks: [N] tasks (T001-TXXX)
   âœ“ Deliverable: [What MVP enables]

   ## Readiness Assessment

   [IF âœ… READY:]
   âœ… All user stories covered with complete task phases
   âœ… All tasks properly formatted and executable
   âœ… Dependencies logical and safe parallelization
   âœ… MVP scope clear and testable
   âœ… Ready to proceed to implementation (/speckit.implement)

   [IF âš ï¸ NEEDS REVIEW:]
   âš ï¸ Minor issues detected:
      - [Issue 1]: [Why low impact]
      - [Issue 2]: [Why low impact]

   Risk: May require task adjustments during implementation.
   Coverage: [X]% (target: 100%)

   [IF âŒ NOT READY:]
   âŒ Critical issues prevent implementation:
      - [Issue 1]: [HIGH impact] - [Why blocks implementation]
      - [Issue 2]: [HIGH impact] - [Why blocks implementation]

   Required Actions:
   1. [Specific fix - e.g., "Add task phases for User Stories 3-5"]
   2. [Specific fix - e.g., "Fix format violations in lines X-Y"]
   3. [Specific fix - e.g., "Resolve circular dependency between US2 and US4"]

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ## Evidence: Task List Details
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   File Info:
   ```
   [Output of: ls -lah FEATURE_DIR/tasks.md]
   ```

   Task Count:
   ```
   [Output of: grep -c "^- \[ \]" tasks.md]
   Total: [N] tasks
   ```

   Format Compliance:
   ```
   Checkboxes: [N]
   Task IDs: [N]
   [P] markers: [X]
   [US] labels: [Y]
   ```

   Phase Breakdown (from tasks.md):
   - Setup: T001-TXXX ([X] tasks)
   - Foundational: TXXX-TYYY ([Y] tasks)
   - User Story phases: TYYY-TZZZ ([Z] tasks)
   - Polish: TZZZ-T[max] ([W] tasks)

   User Story Mapping:
   [Map from spec.md user stories to task phase headers]

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ## Next Steps
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   [IF âœ… READY:]
   1. Start implementation:
      /speckit.implement

   2. Or review task breakdown:
      - Tasks: [path/to/tasks.md]
      - Review specific phase: [which phase]

   3. Or start with MVP first:
      /speckit.implement [MVP scope: User Story 1]

   [IF âš ï¸ NEEDS REVIEW:]
   Choose one:
   1. Proceed with noted risks:
      /speckit.implement

   2. Fix minor issues first:
      [Specific fixes for each issue]

   3. Review tasks:
      [path/to/tasks.md]

   [IF âŒ NOT READY:]
   REQUIRED: Fix critical issues before implementation:

   1. For coverage gaps:
      - Review spec.md user stories
      - Regenerate tasks for missing stories
      - Run /speckit.tasks again

   2. For format issues:
      - Fix task format violations
      - Ensure all tasks have: checkbox, ID, story label, file path
      - Validate with format grep commands

   3. For dependency issues:
      - Review phase structure
      - Fix circular dependencies
      - Ensure foundational phase blocks correctly

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   Ready to proceed? (yes/review tasks/fix issues/start MVP)
   ```

   **User Interaction:**
   ```yaml
   IF user says "yes" or "proceed":
     IF status = READY:
       â†’ Suggest: /speckit.implement
       â†’ Or: /speckit.implement [MVP scope]
     IF status = NEEDS REVIEW:
       â†’ Warn about risks, then suggest: /speckit.implement
     IF status = NOT READY:
       â†’ Block: "Cannot proceed - critical issues in task list"
       â†’ Suggest: /speckit.tasks (regenerate)

   IF user says "review" or "review tasks":
     â†’ Show tasks.md path
     â†’ Offer to display specific phase or user story tasks

   IF user says "fix" or "fix issues":
     â†’ List specific issues with line numbers
     â†’ Suggest fixes for each issue
     â†’ Ask: "Fix automatically or manual edit?"

   IF user says "start MVP" or "MVP":
     â†’ Identify MVP scope (usually User Story 1)
     â†’ List MVP tasks (T001-TXXX)
     â†’ Suggest: /speckit.implement [MVP scope]

   IF EVIDENCE MISSING:
     âŒ "Cannot complete task list review without evidence."
     â†’ List missing evidence
     â†’ Gather evidence automatically where possible
     â†’ Re-run review gate
   ```

   **Benefits** (from PM Agent Reflexion pattern):
   - âœ… Prevents implementation start with incomplete task breakdown
   - âœ… Evidence-based task completeness validation
   - âœ… No false "ready" claims without traceability proof
   - âœ… Transparent validation of task list quality
   - âœ… User confidence in implementation plan

Context for task generation: {ARGS}

The tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context.

## Task Generation Rules

**CRITICAL**: Tasks MUST be organized by user story to enable independent implementation and testing.

**Tests are OPTIONAL**: Only generate test tasks if explicitly requested in the feature specification or if user requests TDD approach.

### Checklist Format (REQUIRED)

Every task MUST strictly follow this format:

```text
- [ ] [TaskID] [P?] [Story?] Description with file path
```

**Format Components**:

1. **Checkbox**: ALWAYS start with `- [ ]` (markdown checkbox)
2. **Task ID**: Sequential number (T001, T002, T003...) in execution order
3. **[P] marker**: Include ONLY if task is parallelizable (different files, no dependencies on incomplete tasks)
4. **[Story] label**: REQUIRED for user story phase tasks only
   - Format: [US1], [US2], [US3], etc. (maps to user stories from spec.md)
   - Setup phase: NO story label
   - Foundational phase: NO story label
   - User Story phases: MUST have story label
   - Polish phase: NO story label
5. **Description**: Clear action with exact file path
6. **Requirement Reference** (NEW v2.3): Add `(_REQ-XX-Y.Z_)` for tasks implementing specific requirements
   - Link to requirement IDs from spec.md (REQ-AUTH-1.1, REQ-DASH-2.1, etc.)
   - Add at end of description when task directly implements a requirement
   - Multiple requirements: `(_REQ-AUTH-1.1, REQ-AUTH-1.2_)`

**Examples**:

- âœ… CORRECT: `- [ ] T001 Create project structure per implementation plan`
- âœ… CORRECT: `- [ ] T005 [P] Implement authentication middleware in src/middleware/auth.py (_REQ-AUTH-1.1_)`
- âœ… CORRECT: `- [ ] T012 [P] [US1] Create User model in src/models/user.py`
- âœ… CORRECT: `- [ ] T014 [US1] Implement UserService with 2-second response time in src/services/user_service.py (_REQ-AUTH-1.1, REQ-AUTH-1.2_)`
- âœ… CORRECT (v2.3): `- [ ] T018 [US1] Add login endpoint POST /api/auth/login in src/routes/auth.py (_REQ-AUTH-1.1_)`
- âŒ WRONG: `- [ ] Create User model` (missing ID and Story label)
- âŒ WRONG: `T001 [US1] Create model` (missing checkbox)
- âŒ WRONG: `- [ ] [US1] Create User model` (missing Task ID)
- âŒ WRONG: `- [ ] T001 [US1] Create model` (missing file path)

### Task Organization

1. **From User Stories (spec.md)** - PRIMARY ORGANIZATION:
   - Each user story (P1, P2, P3...) gets its own phase
   - Map all related components to their story:
     - Models needed for that story
     - Services needed for that story
     - Endpoints/UI needed for that story
     - If tests requested: Tests specific to that story
   - Mark story dependencies (most stories should be independent)

2. **From Requirements (spec.md + plan.md)** - NEW v2.3 TRACEABILITY:
   - Extract requirement IDs from spec.md (REQ-XX-Y.Z format)
   - Extract requirement references from plan.md phases (_Requirements: REQ-XX-Y.Z_)
   - For each task that implements a requirement:
     - Add requirement reference at end: `(_REQ-XX-Y.Z_)`
     - Multiple requirements: `(_REQ-XX-1.1, REQ-XX-1.2_)`
   - This enables full traceability: spec.md â†’ plan.md â†’ tasks.md â†’ tests

3. **From Contracts**:
   - Map each contract/endpoint â†’ to the user story it serves
   - If tests requested: Each contract â†’ contract test task [P] before implementation in that story's phase

4. **From Data Model**:
   - Map each entity to the user story(ies) that need it
   - If entity serves multiple stories: Put in earliest story or Setup phase
   - Relationships â†’ service layer tasks in appropriate story phase

5. **From Setup/Infrastructure**:
   - Shared infrastructure â†’ Setup phase (Phase 1)
   - Foundational/blocking tasks â†’ Foundational phase (Phase 2)
   - Story-specific setup â†’ within that story's phase

### Phase Structure

- **Phase 1**: Setup (project initialization)
- **Phase 2**: Foundational (blocking prerequisites - MUST complete before user stories)
- **Phase 3+**: User Stories in priority order (P1, P2, P3...)
  - Within each story: Tests (if requested) â†’ Models â†’ Services â†’ Endpoints â†’ Integration
  - Each phase should be a complete, independently testable increment
- **Final Phase**: Polish & Cross-Cutting Concerns

---

## Final Step: Update Specification Metadata

After generating tasks.md, update `spec-metadata.json` in the spec directory:

```json
{
  "phase": "tasks",
  "approvals": {
    "tasks": {
      "generated": true,
      "approved": false,
      "timestamp": "{ISO 8601 timestamp}"
    }
  },
  "metadata": {
    "updated_at": "{ISO 8601 timestamp}"
  }
}
```

**Recommend Next Steps**:
- "âœ… Tasks generated. Review tasks-N.md and run `/speckit.implement` to begin implementation"
- "Or run `/speckit.status` to check current workflow state"
- IF test-first workflow: "Run tests (they should fail), then implement to make them pass"
